{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84ea169c-b825-4d9f-9700-6b0dc15a49a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For text preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "#For topic modelling\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "#Download NLTK Resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "603e97bb-cf02-403a-8598-583db57510e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>I recently posted an article asking what kind ...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>\\nIt depends on your priorities.  A lot of peo...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>an excellent automatic can be found in the sub...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>: Ford and his automobile.  I need information...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  target  \\\n",
       "0           0  I was wondering if anyone out there could enli...       7   \n",
       "1          17  I recently posted an article asking what kind ...       7   \n",
       "2          29  \\nIt depends on your priorities.  A lot of peo...       7   \n",
       "3          56  an excellent automatic can be found in the sub...       7   \n",
       "4          64  : Ford and his automobile.  I need information...       7   \n",
       "\n",
       "       title                        date  \n",
       "0  rec.autos  2022-08-02 13:48:37.251043  \n",
       "1  rec.autos  2022-08-02 13:48:37.251043  \n",
       "2  rec.autos  2022-08-02 13:48:37.251043  \n",
       "3  rec.autos  2022-08-02 13:48:37.251043  \n",
       "4  rec.autos  2022-08-02 13:48:37.251043  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('news_dataset.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7c08be0-49d1-484e-a06e-31d0c476bbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of 0        I was wondering if anyone out there could enli...\n",
       "1        I recently posted an article asking what kind ...\n",
       "2        \\nIt depends on your priorities.  A lot of peo...\n",
       "3        an excellent automatic can be found in the sub...\n",
       "4        : Ford and his automobile.  I need information...\n",
       "                               ...                        \n",
       "11309    Secrecy in Clipper Chip\\n\\nThe serial number o...\n",
       "11310    Hi !\\n\\nI am interested in the source of FEAL ...\n",
       "11311    The actual algorithm is classified, however, t...\n",
       "11312    \\n\\tThis appears to be generic calling upon th...\n",
       "11313    \\nProbably keep quiet and take it, lest they g...\n",
       "Name: text, Length: 11314, dtype: object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data = df['text']\n",
    "\n",
    "text_data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fed59048-110b-47ca-a02c-35e2b13f57f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [wonder, anyon, could, enlighten, car, saw, da...\n",
       "1    [recent, post, articl, ask, kind, rate, singl,...\n",
       "2    [depend, prioriti, lot, peopl, put, higher, pr...\n",
       "3    [excel, automat, found, subaru, legaci, switch...\n",
       "4    [ford, automobil, need, inform, whether, ford,...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Remove null values\n",
    "text_data = text_data.dropna()\n",
    "\n",
    "# 2. Initialize preprocessing tools\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# 3. Define preprocessing function\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # Remove punctuation and numbers\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return tokens\n",
    "\n",
    "# 4. Apply preprocessing\n",
    "preprocessed_texts = text_data.apply(preprocess)\n",
    "\n",
    "# Preview\n",
    "preprocessed_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f2203ff-78e0-452b-ab28-cb37b967233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Gensim Dictionary object from the preprocessed documents\n",
    "dictionary = corpora.Dictionary(preprocessed_texts)\n",
    "\n",
    "# Filter out tokens that appear in less than 15 documents or more than 50% of the documents\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5)\n",
    "\n",
    "# Convert each preprocessed document into a bag-of-words representation using the dictionary\n",
    "corpus = [dictionary.doc2bow(doc) for doc in preprocessed_texts] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b836a72e-869a-48da-bc81-590a89e30c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Run LDA\n",
    "lda_model = LdaModel(corpus, num_topics=5, id2word=dictionary, passes=15)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "039c8885-965f-40db-999e-b2e4fdaea2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Interpret Results: Find the dominant topic for each document\n",
    "article_labels = []\n",
    "\n",
    "# Iterate over each preprocessed document\n",
    "for i, doc in enumerate(preprocessed_texts):\n",
    "    # Convert to bag-of-words representation\n",
    "    bow = dictionary.doc2bow(doc)\n",
    "    \n",
    "    # Get the list of topic probabilities\n",
    "    topics = lda_model.get_document_topics(bow)\n",
    "    \n",
    "    # Determine the topic with the highest probability\n",
    "    dominant_topic = max(topics, key=lambda x: x[1])[0]\n",
    "    \n",
    "    # Append to the list\n",
    "    article_labels.append(dominant_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a35b940-9915-4781-b5a3-371f2e4b056b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table with Articles and Topic:\n",
      "                                                 Article  Topic\n",
      "0      I was wondering if anyone out there could enli...      0\n",
      "1      I recently posted an article asking what kind ...      3\n",
      "2      \\nIt depends on your priorities.  A lot of peo...      3\n",
      "3      an excellent automatic can be found in the sub...      3\n",
      "4      : Ford and his automobile.  I need information...      3\n",
      "...                                                  ...    ...\n",
      "11309  Secrecy in Clipper Chip\\n\\nThe serial number o...      2\n",
      "11310  Hi !\\n\\nI am interested in the source of FEAL ...      3\n",
      "11311  The actual algorithm is classified, however, t...      2\n",
      "11312  \\n\\tThis appears to be generic calling upon th...      0\n",
      "11313  \\nProbably keep quiet and take it, lest they g...      0\n",
      "\n",
      "[11096 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 6. Create a DataFrame\n",
    "df_result = pd.DataFrame({\"Article\": text_data, \"Topic\": article_labels})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(\"Table with Articles and Topic:\")\n",
    "print(df_result)\n",
    "\n",
    "# Optionally, evaluate the LDA model using coherence score\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Calculate coherence score using the preprocessed texts\n",
    "coherence_model = CoherenceModel(model=lda_model, corpus=corpus, dictionary=dictionary, texts=preprocessed_texts, coherence='c_v')\n",
    "coherence_score = coherence_model.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "24a75c30-d76a-47d9-9ef5-3a105f3ec8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Name: Mysara Qistina binti Mahadzir & Addelina binti Mohd Zulkifli\n",
      "\n",
      "Student ID: SW01083524 & SW01082366\n",
      "\n",
      "Coherence Score: 0.5481828341197291\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Name: Mysara Qistina binti Mahadzir & Addelina binti Mohd Zulkifli\")\n",
    "print(\"\\nStudent ID: SW01083524 & SW01082366\")\n",
    "\n",
    "print(\"\\nCoherence Score:\", coherence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "28b199ac-0502-4145-baef-5c6895736fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms for Topic #0:\n",
      "['one', 'would', 'dont', 'think', 'know', 'say', 'like', 'go', 'get', 'peopl']\n",
      "\n",
      "Top terms for Topic #1:\n",
      "['peopl', 'govern', 'would', 'state', 'law', 'q', 'right', 'u', 'one', 'mr']\n",
      "\n",
      "Top terms for Topic #2:\n",
      "['key', 'encrypt', 'use', 'chip', 'secur', 'system', 'inform', 'anonym', 'post', 'clipper']\n",
      "\n",
      "Top terms for Topic #3:\n",
      "['use', 'b', 'db', 'one', 'would', 'get', 'drive', 'work', 'like', 'know']\n",
      "\n",
      "Top terms for Topic #4:\n",
      "['x', 'file', 'use', 'program', 'window', 'version', 'includ', 'avail', 'space', 'c']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print top terms for each topic\n",
    "for topic_id in range(lda_model.num_topics):\n",
    "    print(f\"Top terms for Topic #{topic_id}:\")\n",
    "    top_terms = lda_model.show_topic(topic_id, topn=10)\n",
    "    print([term[0] for term in top_terms])  # Extracting the top terms from the result\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "79e4facb-066d-485b-89e9-9112b79d0fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Terms for Each Topic:\n",
      "Topic 0:\n",
      "- \"one\" (weight: 0.010)\n",
      "- \"would\" (weight: 0.009)\n",
      "- \"dont\" (weight: 0.009)\n",
      "- \"think\" (weight: 0.008)\n",
      "- \"know\" (weight: 0.007)\n",
      "- \"say\" (weight: 0.007)\n",
      "- \"like\" (weight: 0.007)\n",
      "- \"go\" (weight: 0.007)\n",
      "- \"get\" (weight: 0.007)\n",
      "- \"peopl\" (weight: 0.006)\n",
      "\n",
      "Topic 1:\n",
      "- \"peopl\" (weight: 0.009)\n",
      "- \"govern\" (weight: 0.008)\n",
      "- \"would\" (weight: 0.008)\n",
      "- \"state\" (weight: 0.006)\n",
      "- \"law\" (weight: 0.006)\n",
      "- \"q\" (weight: 0.006)\n",
      "- \"right\" (weight: 0.005)\n",
      "- \"u\" (weight: 0.005)\n",
      "- \"one\" (weight: 0.005)\n",
      "- \"mr\" (weight: 0.005)\n",
      "\n",
      "Topic 2:\n",
      "- \"key\" (weight: 0.025)\n",
      "- \"encrypt\" (weight: 0.016)\n",
      "- \"use\" (weight: 0.016)\n",
      "- \"chip\" (weight: 0.011)\n",
      "- \"secur\" (weight: 0.010)\n",
      "- \"system\" (weight: 0.009)\n",
      "- \"inform\" (weight: 0.009)\n",
      "- \"anonym\" (weight: 0.008)\n",
      "- \"post\" (weight: 0.008)\n",
      "- \"clipper\" (weight: 0.008)\n",
      "\n",
      "Topic 3:\n",
      "- \"use\" (weight: 0.016)\n",
      "- \"b\" (weight: 0.014)\n",
      "- \"db\" (weight: 0.013)\n",
      "- \"one\" (weight: 0.009)\n",
      "- \"would\" (weight: 0.009)\n",
      "- \"get\" (weight: 0.009)\n",
      "- \"drive\" (weight: 0.008)\n",
      "- \"work\" (weight: 0.007)\n",
      "- \"like\" (weight: 0.007)\n",
      "- \"know\" (weight: 0.007)\n",
      "\n",
      "Topic 4:\n",
      "- \"x\" (weight: 0.049)\n",
      "- \"file\" (weight: 0.016)\n",
      "- \"use\" (weight: 0.015)\n",
      "- \"program\" (weight: 0.010)\n",
      "- \"window\" (weight: 0.008)\n",
      "- \"version\" (weight: 0.006)\n",
      "- \"includ\" (weight: 0.006)\n",
      "- \"avail\" (weight: 0.006)\n",
      "- \"space\" (weight: 0.006)\n",
      "- \"c\" (weight: 0.005)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the top terms for each topic with their weights\n",
    "print(\"Top Terms for Each Topic:\")\n",
    "for idx, topic in lda_model.print_topics():\n",
    "    print(f\"Topic {idx}:\")\n",
    "    terms = [term.strip() for term in topic.split(\" + \")]\n",
    "    for term in terms:\n",
    "        weight, word = term.split(\"*\")\n",
    "        print(f\"- {word.strip()} (weight: {weight.strip()})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393b10b0-6429-4803-8483-aaf799c429ce",
   "metadata": {},
   "source": [
    "#### Topic 0: General\n",
    "#### Topic 1: Politics \n",
    "#### Topic 2: Security\n",
    "#### Topic 3: Technology\n",
    "#### Topic 4: Software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2fb445-94d3-4971-bed6-4455ff6a001b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
